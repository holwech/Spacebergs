{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1471, 7) (133, 7)\n",
      "CPU times: user 9.4 s, sys: 5.43 s, total: 14.8 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "train = pd.read_json(\"../data/train.json\").fillna(-1.0).replace('na', -1.0)\n",
    "test = pd.read_json(\"../data/test.json\").fillna(-1.0).replace('na', -1.0)\n",
    "train['angle_l'] = train['inc_angle'].apply(lambda x: len(str(x))) <= 7\n",
    "test['angle_l'] = test['inc_angle'].apply(lambda x: len(str(x))) <= 7\n",
    "train['null_angle'] = (train['inc_angle']==-1).values\n",
    "test['null_angle'] = (test['inc_angle']==-1).values\n",
    "x1 = train[train['inc_angle']!= -1.0]\n",
    "x2 = train[train['inc_angle']== -1.0]\n",
    "del train;\n",
    "print(x1.values.shape, x2.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 7)\n",
      "CPU times: user 10.9 s, sys: 4.62 s, total: 15.5 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "pca_b1 = decomposition.PCA(n_components=50, whiten=False, random_state=12)\n",
    "pca_b2 = decomposition.PCA(n_components=50, whiten=False, random_state=13)\n",
    "etc = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=7, n_jobs=-1, random_state=14)\n",
    "\n",
    "band1 = [np.array(band).astype(np.float32).flatten() for band in x1[\"band_1\"]]\n",
    "band2 = [np.array(band).astype(np.float32).flatten() for band in x1[\"band_2\"]]\n",
    "band1 = pd.DataFrame(pca_b1.fit_transform(band1))\n",
    "band1.columns = [str(c)+'_1' for c in band1.columns]\n",
    "band2 = pd.DataFrame(pca_b2.fit_transform(band2))\n",
    "band2.columns = [str(c)+'_2' for c in band2.columns]\n",
    "features = pd.concat((band1, band2), axis=1, ignore_index=True)\n",
    "etc.fit(features, x1.inc_angle)\n",
    "\n",
    "band1 = [np.array(band).astype(np.float32).flatten() for band in x2[\"band_1\"]]\n",
    "band2 = [np.array(band).astype(np.float32).flatten() for band in x2[\"band_2\"]]\n",
    "band1 = pd.DataFrame(pca_b1.transform(band1))\n",
    "band1.columns = [str(c)+'_1' for c in band1.columns]\n",
    "band2 = pd.DataFrame(pca_b2.fit_transform(band2))\n",
    "band2.columns = [str(c)+'_2' for c in band2.columns]\n",
    "features = pd.concat((band1, band2), axis=1, ignore_index=True)\n",
    "x2['inc_angle'] = etc.predict(features)\n",
    "\n",
    "train = pd.concat((x1, x2), axis=0, ignore_index=True).reset_index(drop=True)\n",
    "del x1; del x2;\n",
    "print(train.values.shape)\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 7.91 s, total: 30.2 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca_b1 = decomposition.PCA(n_components=50, whiten=True, random_state=15)\n",
    "pca_b2 = decomposition.PCA(n_components=50, whiten=True, random_state=16)\n",
    "pca_b3 = decomposition.PCA(n_components=50, whiten=True, random_state=17)\n",
    "pca_b4 = decomposition.PCA(n_components=50, whiten=True, random_state=18)\n",
    "\n",
    "band1 = [np.array(band).astype(np.float32).flatten() for band in train[\"band_1\"]]\n",
    "band2 = [np.array(band).astype(np.float32).flatten() for band in train[\"band_2\"]]\n",
    "pd_band1 = pd.DataFrame(band1)\n",
    "pd_band2 = pd.DataFrame(band2)\n",
    "pd_band3 = pd.DataFrame(np.dot(np.diag(train['inc_angle'].values), ((pd_band1 + pd_band2) / 2)))\n",
    "pd_band4 = pd.DataFrame(np.dot(np.diag(train['inc_angle'].values), ((pd_band1 - pd_band2) / 2)))\n",
    "band1 = pd.DataFrame(pca_b1.fit_transform(pd_band1))\n",
    "band1.columns = [str(c)+'_1' for c in band1.columns]\n",
    "band2 = pd.DataFrame(pca_b2.fit_transform(pd_band2))\n",
    "band2.columns = [str(c)+'_2' for c in band2.columns]\n",
    "band3 = pd.DataFrame(pca_b3.fit_transform(pd_band3.values))\n",
    "band3.columns = [str(c)+'_3' for c in band3.columns]\n",
    "band4 = pd.DataFrame(pca_b4.fit_transform(pd_band4.values))\n",
    "band4.columns = [str(c)+'_4' for c in band4.columns]\n",
    "features = pd.concat((band1, band2, band3, band4), axis=1, ignore_index=True).reset_index(drop=True)\n",
    "features['inc_angle'] = train['inc_angle']\n",
    "features['angle_l'] = train['angle_l']\n",
    "features['null_angle'] = train['null_angle']\n",
    "features['band1_min'] = pd_band1.min(axis=1, numeric_only=True)\n",
    "features['band2_min'] = pd_band2.min(axis=1, numeric_only=True)\n",
    "features['band3_min'] = pd_band3.min(axis=1, numeric_only=True)\n",
    "features['band4_min'] = pd_band4.min(axis=1, numeric_only=True)\n",
    "features['band1_max'] = pd_band1.max(axis=1, numeric_only=True)\n",
    "features['band2_max'] = pd_band2.max(axis=1, numeric_only=True)\n",
    "features['band3_max'] = pd_band3.max(axis=1, numeric_only=True)\n",
    "features['band4_max'] = pd_band4.max(axis=1, numeric_only=True)\n",
    "features['band1_med'] = pd_band1.median(axis=1, numeric_only=True)\n",
    "features['band2_med'] = pd_band2.median(axis=1, numeric_only=True)\n",
    "features['band3_med'] = pd_band3.median(axis=1, numeric_only=True)\n",
    "features['band4_med'] = pd_band4.median(axis=1, numeric_only=True)\n",
    "features['band1_mea'] = pd_band1.mean(axis=1, numeric_only=True)\n",
    "features['band2_mea'] = pd_band2.mean(axis=1, numeric_only=True)\n",
    "features['band3_mea'] = pd_band3.mean(axis=1, numeric_only=True)\n",
    "features['band4_mea'] = pd_band4.mean(axis=1, numeric_only=True)\n",
    "del pd_band1; del pd_band2; del pd_band3; del pd_band4\n",
    "features1 = features.copy()\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 21.2 s, total: 3min 10s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "band1 = [np.array(band).astype(np.float32).flatten() for band in test[\"band_1\"]]\n",
    "band2 = [np.array(band).astype(np.float32).flatten() for band in test[\"band_2\"]]\n",
    "pd_band1 = pd.DataFrame(band1)\n",
    "pd_band2 = pd.DataFrame(band2)\n",
    "pd_band3 = pd.DataFrame(np.dot(np.diag(test['inc_angle'].values), ((pd_band1 + pd_band2) / 2)))\n",
    "pd_band4 = pd.DataFrame(np.dot(np.diag(test['inc_angle'].values), ((pd_band1 - pd_band2) / 2)))\n",
    "band1 = pd.DataFrame(pca_b1.transform(pd_band1))\n",
    "band1.columns = [str(c)+'_1' for c in band1.columns]\n",
    "band2 = pd.DataFrame(pca_b2.transform(pd_band2))\n",
    "band2.columns = [str(c)+'_2' for c in band2.columns]\n",
    "band3 = pd.DataFrame(pca_b3.transform(pd_band3.values))\n",
    "band3.columns = [str(c)+'_3' for c in band3.columns]\n",
    "band4 = pd.DataFrame(pca_b4.fit_transform(pd_band4.values))\n",
    "band4.columns = [str(c)+'_4' for c in band4.columns]\n",
    "features = pd.concat((band1, band2, band3, band4), axis=1, ignore_index=True).reset_index(drop=True)\n",
    "features['inc_angle'] = test['inc_angle']\n",
    "features['angle_l'] = test['angle_l']\n",
    "features['null_angle'] = test['null_angle']\n",
    "features['band1_min'] = pd_band1.min(axis=1, numeric_only=True)\n",
    "features['band2_min'] = pd_band2.min(axis=1, numeric_only=True)\n",
    "features['band3_min'] = pd_band3.min(axis=1, numeric_only=True)\n",
    "features['band4_min'] = pd_band4.min(axis=1, numeric_only=True)\n",
    "features['band1_max'] = pd_band1.max(axis=1, numeric_only=True)\n",
    "features['band2_max'] = pd_band2.max(axis=1, numeric_only=True)\n",
    "features['band3_max'] = pd_band3.max(axis=1, numeric_only=True)\n",
    "features['band4_max'] = pd_band4.max(axis=1, numeric_only=True)\n",
    "features['band1_med'] = pd_band1.median(axis=1, numeric_only=True)\n",
    "features['band2_med'] = pd_band2.median(axis=1, numeric_only=True)\n",
    "features['band3_med'] = pd_band3.median(axis=1, numeric_only=True)\n",
    "features['band4_med'] = pd_band4.median(axis=1, numeric_only=True)\n",
    "features['band1_mea'] = pd_band1.mean(axis=1, numeric_only=True)\n",
    "features['band2_mea'] = pd_band2.mean(axis=1, numeric_only=True)\n",
    "features['band3_mea'] = pd_band3.mean(axis=1, numeric_only=True)\n",
    "features['band4_mea'] = pd_band4.mean(axis=1, numeric_only=True)\n",
    "del pd_band1; del pd_band2; del pd_band3\n",
    "features2 = features.copy()\n",
    "features.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM... 0\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "b\"Objective and metrics don't match\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;34m\"\"\"construct booster\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    820\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m    823\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, max_bin, reference, weight, group, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: b\"Objective and metrics don't match\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "lgb_models = []\n",
    "#xgb_models = []\n",
    "test['is_iceberg'] = 0.\n",
    "fold = 5\n",
    "for i in range(fold):\n",
    "    np.random.seed(i)\n",
    "    random.seed(i)\n",
    "    x1, x2, y1, y2 = model_selection.train_test_split(features1.astype(float), train['is_iceberg'].values, test_size=0.2, random_state=i)\n",
    "\n",
    "    #print('XGB...', i)\n",
    "    #params = {'eta': 0.02, 'max_depth': 4, 'objective': 'multi:softprob', 'eval_metric': 'mlogloss', 'num_class': 2, 'seed': i, 'silent': True}\n",
    "    #watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    #xgb_models.append(xgb.train(params, xgb.DMatrix(x1, y1), 2000,  watchlist, verbose_eval=500, early_stopping_rounds=200))\n",
    "\n",
    "    print('LightGBM...', i)\n",
    "    params = {'learning_rate': 0.02, 'max_depth': 7, 'boosting_type': 'gbdt', 'objective': 'multiclass', 'metric' : 'multi_logloss', 'is_training_metric': True, 'num_class': 2, 'seed': i}\n",
    "    lgb_models.append(lgb.train(params, lgb.Dataset(x1, label=y1), 2000, lgb.Dataset(x2, label=y2), verbose_eval=500, early_stopping_rounds=200))\n",
    "    \n",
    "    #test['is_iceberg'] += xgb_models[i].predict(xgb.DMatrix(features2), ntree_limit=xgb_models[i].best_ntree_limit)[:, 1]\n",
    "    test['is_iceberg'] += lgb_models[i].predict(features2, num_iteration=lgb_models[i].best_iteration)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_iceberg'] = test['is_iceberg'].clip(0.+1e-15,1.-1e-15)\n",
    "test[['id','is_iceberg']].to_csv(\"../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
