{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Chia-Ta Tsai\n",
    "#blended with two GBMs (XGBoost and LightGBM)\n",
    "#feature transformation was originally from the1owl's kernel, 'Natural Growth Patterns' but refactered afterward. Forked from\n",
    "#https://www.kaggle.com/the1owl/natural-growth-patterns-fractals-of-nature\n",
    "\n",
    "**Updates\n",
    "ver07: add garbage collect\n",
    "ver06: reverted to ver04 and added footnotes\n",
    "ver05: LB 0.2093\n",
    "ver04: LB 0.2021\n",
    "\"\"\"\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import datetime as dt\n",
    "#\n",
    "from random import choice, sample, shuffle, uniform, seed\n",
    "from math import exp, expm1, log1p, log10, log2, sqrt, ceil, floor, isfinite, isnan\n",
    "from itertools import combinations\n",
    "#import for image processing\n",
    "import cv2\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.ndimage import laplace, sobel\n",
    "#evaluation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "STORE_PATH = \"../data/boost/\"\n",
    "\n",
    "###############################################################################\n",
    "def read_jason(file='', loc='../input/'):\n",
    "\n",
    "    df = pd.read_json('{}{}'.format(loc, file))\n",
    "    df['inc_angle'] = df['inc_angle'].replace('na', -1).astype(float)\n",
    "    #print(df['inc_angle'].value_counts())\n",
    "    \n",
    "    band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n",
    "    band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n",
    "    band1_imf1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1_imf_1\"]])\n",
    "    band1_imf2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1_imf_2\"]])\n",
    "    band2_imf1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2_imf_1\"]])\n",
    "    band2_imf2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2_imf_2\"]])\n",
    "    df = df.drop(['band_1', 'band_2'], axis=1)\n",
    "    \n",
    "    bands = np.stack((band1, band2,  0.5 * (band1 + band2), band1_imf1, band1_imf2, band2_imf1, band2_imf2), axis=-1)\n",
    "    del band1, band2, band1_imf1, band1_imf2, band2_imf1, band2_imf2\n",
    "    \n",
    "    return df, bands\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def run_lgb(params={}, lgb_train=None, lgb_valid=None, lgb_test=None, test_ids=None, nr_round=2000, min_round=100, file=''):\n",
    "\n",
    "    print('\\nLightGBM: {}'.format(params['boosting'])) \n",
    "    model2 = lgb.train(params, \n",
    "                       lgb_train, \n",
    "                       nr_round, \n",
    "                       lgb_valid, \n",
    "                       verbose_eval=50, early_stopping_rounds=min_round)\n",
    "    \n",
    "    pred = model2.predict(lgb_test, num_iteration=model2.best_iteration)\n",
    "    #\n",
    "    subm = pd.DataFrame({'id': test_ids, 'is_iceberg': pred})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    #   \n",
    "    df = pd.DataFrame({'feature':model2.feature_name(), 'importances': model2.feature_importance()})\n",
    "    \n",
    "    return pred, df\n",
    "\n",
    "###############################################################################\n",
    "#forked from\n",
    "#https://www.kaggle.com/the1owl/planet-understanding-the-amazon-from-space/natural-growth-patterns-fractals-of-nature/notebook\n",
    "def img_to_stats(paths):\n",
    "    \n",
    "    img_id, img = paths[0], paths[1]\n",
    "    \n",
    "    #ignored error    \n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    bins = 20\n",
    "    scl_min, scl_max = -50, 50\n",
    "    opt_poly = True\n",
    "    #opt_poly = False\n",
    "    \n",
    "    try:\n",
    "        st = []\n",
    "        st_interv = []\n",
    "        hist_interv = []\n",
    "        for i in range(img.shape[2]):\n",
    "            img_sub = np.squeeze(img[:, :, i])\n",
    "            \n",
    "            #median, max and min\n",
    "            sub_st = []\n",
    "            sub_st += [np.mean(img_sub), np.std(img_sub), np.max(img_sub), np.median(img_sub), np.min(img_sub)]\n",
    "            sub_st += [(sub_st[2] - sub_st[3]), (sub_st[2] - sub_st[4]), (sub_st[3] - sub_st[4])] \n",
    "            sub_st += [(sub_st[-3] / sub_st[1]), (sub_st[-2] / sub_st[1]), (sub_st[-1] / sub_st[1])] #normalized by stdev\n",
    "            st += sub_st\n",
    "            #Laplacian, Sobel, kurtosis and skewness\n",
    "            st_trans = []\n",
    "            st_trans += [laplace(img_sub, mode='reflect', cval=0.0).ravel().var()] #blurr\n",
    "            sobel0 = sobel(img_sub, axis=0, mode='reflect', cval=0.0).ravel().var()\n",
    "            sobel1 = sobel(img_sub, axis=1, mode='reflect', cval=0.0).ravel().var()\n",
    "            st_trans += [sobel0, sobel1]\n",
    "            st_trans += [kurtosis(img_sub.ravel()), skew(img_sub.ravel())]\n",
    "            \n",
    "            if opt_poly:\n",
    "                st_interv.append(sub_st)\n",
    "                #\n",
    "                st += [x * y for x, y in combinations(st_trans, 2)]\n",
    "                st += [x + y for x, y in combinations(st_trans, 2)]\n",
    "                st += [x - y for x, y in combinations(st_trans, 2)]                \n",
    " \n",
    "            #hist\n",
    "            #hist = list(cv2.calcHist([img], [i], None, [bins], [0., 1.]).flatten())\n",
    "            hist = list(np.histogram(img_sub, bins=bins, range=(scl_min, scl_max))[0])\n",
    "            hist_interv.append(hist)\n",
    "            st += hist\n",
    "            st += [hist.index(max(hist))] #only the smallest index w/ max value would be incl\n",
    "            st += [np.std(hist), np.max(hist), np.median(hist), (np.max(hist) - np.median(hist))]\n",
    "\n",
    "        if opt_poly:\n",
    "            for x, y in combinations(st_interv, 2):\n",
    "                st += [float(x[j]) * float(y[j]) for j in range(len(st_interv[0]))]\n",
    "\n",
    "            for x, y in combinations(hist_interv, 2):\n",
    "                hist_diff = [x[j] * y[j] for j in range(len(hist_interv[0]))]\n",
    "                st += [hist_diff.index(max(hist_diff))] #only the smallest index w/ max value would be incl\n",
    "                st += [np.std(hist_diff), np.max(hist_diff), np.median(hist_diff), (np.max(hist_diff) - np.median(hist_diff))]\n",
    "                \n",
    "        #correction\n",
    "        nan = -999\n",
    "        for i in range(len(st)):\n",
    "            if isnan(st[i]) == True:\n",
    "                st[i] = nan\n",
    "                \n",
    "    except:\n",
    "        print('except: ')\n",
    "    \n",
    "    return [img_id, st]\n",
    "\n",
    "\n",
    "def extract_img_stats(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(8) #(cpu_count())\n",
    "    ret = p.map(img_to_stats, paths)\n",
    "    for i in tqdm(range(len(ret)), miniters=100):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "\n",
    "    ret = []\n",
    "    fdata = [imf_d[i] for i, j in paths]\n",
    "    return np.array(fdata, dtype=np.float32)\n",
    "\n",
    "\n",
    "def process(df, bands):\n",
    "\n",
    "    data = extract_img_stats([(k, v) for k, v in zip(df['id'].tolist(), bands)]); gc.collect()\n",
    "    data = np.concatenate([data, df['inc_angle'].values[:, np.newaxis]], axis=-1); gc.collect()\n",
    "\n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "###############################################################################\n",
    "def save_blend(preds={}, loc='./'):\n",
    "    \n",
    "    target = 'is_iceberg'\n",
    "    \n",
    "    w_total = 0.0\n",
    "    blend = None\n",
    "    df_corr = None\n",
    "    print('\\nBlending...')\n",
    "    for k, v in preds.items():\n",
    "        if blend is None:\n",
    "            blend = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            \n",
    "            df_corr = pd.DataFrame({'id': blend['id'].tolist()})\n",
    "            df_corr[k[16:-4]] = blend[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] = blend[target] * v\n",
    "                \n",
    "        else:\n",
    "            preds_tmp = pd.read_csv('{0}/{1}'.format(loc, k))\n",
    "            preds_tmp = blend[['id']].merge(preds_tmp, how='left', on='id')\n",
    "            print('load: {0}, w={1}'.format(k, v))\n",
    "            df_corr[k[16:-4]] = preds_tmp[target]\n",
    "            \n",
    "            w_total += v\n",
    "            blend[target] += preds_tmp[target] * v\n",
    "            del preds_tmp\n",
    "            \n",
    "    print('\\n{}'.format(df_corr.corr()), flush=True)\n",
    "    #write submission\n",
    "    blend[target] = blend[target] / w_total\n",
    "    print('\\nPreview: \\n{}'.format(blend.head()), flush=True)\n",
    "    blend.to_csv(STORE_PATH + '{}subm_blend{:03d}_{}.csv'.format(loc, len(preds), tmp), index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'band_1_imf_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'band_1_imf_1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-79f13e7e92e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_jason\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_jason\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-47f935bf99c0>\u001b[0m in \u001b[0;36mread_jason\u001b[0;34m(file, loc)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mband1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"band_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mband2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"band_2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mband1_imf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"band_1_imf_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mband1_imf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"band_1_imf_2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mband2_imf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"band_2_imf_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'band_1_imf_1'"
     ]
    }
   ],
   "source": [
    "np.random.seed(1017)\n",
    "target = 'is_iceberg'\n",
    "\n",
    "#Load data\n",
    "train, train_bands = read_jason(file='train.json', loc='../data/')\n",
    "test, test_bands = read_jason(file='test.json', loc='../data/')\n",
    "\n",
    "train_X = process(df=train, bands=train_bands)\n",
    "train_y = train[target].values\n",
    "\n",
    "test_X = process(df=test, bands=test_bands)\n",
    "\n",
    "#results\n",
    "freq = pd.DataFrame()\n",
    "subms = []\n",
    "\n",
    "#training\n",
    "test_ratio = 0.2\n",
    "nr_runs = 3\n",
    "split_seed = 25\n",
    "kf = StratifiedShuffleSplit(n_splits=nr_runs, test_size=test_ratio, train_size=None, random_state=split_seed)\n",
    "\n",
    "for r, (train_index, test_index) in enumerate(kf.split(train_X, train_y)):\n",
    "    print('\\nround {:04d} of {:04d}, seed={}'.format(r+1, nr_runs, split_seed))\n",
    "\n",
    "    tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "    x1, x2 = train_X[train_index], train_X[test_index]\n",
    "    y1, y2 = train_y[train_index], train_y[test_index]\n",
    "    #x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=test_ratio, random_state=split_seed + r)\n",
    "    print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "    test_X_dup = test_X.copy()\n",
    "\n",
    "    #XGB\n",
    "    xgb_train = xgb.DMatrix(x1, y1)\n",
    "    xgb_valid = xgb.DMatrix(x2, y2)\n",
    "    #\n",
    "    watchlist = [(xgb_train, 'train'), (xgb_valid, 'valid')]\n",
    "    params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "    params['eta'] = 0.03\n",
    "    params['max_depth'] = 4\n",
    "    params['subsample'] = 0.9\n",
    "    params['eval_metric'] = 'logloss'\n",
    "    params['colsample_bytree'] = 0.8\n",
    "    params['colsample_bylevel'] = 0.8\n",
    "    params['max_delta_step'] = 3\n",
    "    #params['gamma'] = 5.0\n",
    "    #params['labmda'] = 1\n",
    "    params['scale_pos_weight'] = 1.0\n",
    "    params['seed'] = split_seed + r\n",
    "    nr_round = 2000\n",
    "    min_round = 100\n",
    "\n",
    "    model1 = xgb.train(params, \n",
    "                       xgb_train, \n",
    "                       nr_round,  \n",
    "                       watchlist, \n",
    "                       verbose_eval=50, \n",
    "                       early_stopping_rounds=min_round)\n",
    "\n",
    "    pred_xgb = model1.predict(xgb.DMatrix(test_X_dup), ntree_limit=model1.best_ntree_limit+45)\n",
    "\n",
    "    #\n",
    "    file = STORE_PATH + 'subm_{}_xgb_{:02d}.csv'.format(tmp, r+1)\n",
    "    subm = pd.DataFrame({'id': test['id'].values, target: pred_xgb})\n",
    "    subm.to_csv(file, index=False, float_format='%.6f')\n",
    "    subms.append(file)    \n",
    "\n",
    "    ##LightGBM\n",
    "    lgb_train = lgb.Dataset(x1, label=y1, free_raw_data=False)\n",
    "    lgb_valid = lgb.Dataset(x2, label=y2, reference=lgb_train, free_raw_data=False)\n",
    "    #gbdt\n",
    "    params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "    params['boosting'] = 'gbdt'\n",
    "    params['metric'] = 'binary_logloss'\n",
    "    params['learning_rate'] = 0.03\n",
    "    params['max_depth'] = 5\n",
    "    params['num_leaves'] = 16 # higher number of leaves\n",
    "    params['feature_fraction'] = 0.8 # Controls overfit\n",
    "    params['bagging_fraction'] = 0.9    \n",
    "    params['bagging_freq'] = 3\n",
    "    params['seed'] = split_seed + r\n",
    "    #\n",
    "    params['verbose'] = -1\n",
    "\n",
    "    file = STORE_PATH + 'subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "    subms.append(file)\n",
    "\n",
    "    pred, f_tmp = run_lgb(params=params, \n",
    "                          lgb_train=lgb_train, \n",
    "                          lgb_valid=lgb_valid, \n",
    "                          lgb_test=test_X_dup, \n",
    "                          test_ids=test['id'].values, \n",
    "                          nr_round=nr_round, \n",
    "                          min_round=min_round, \n",
    "                          file=file)\n",
    "\n",
    "    ##LightGBM\n",
    "    #dart\n",
    "    params = {'learning_rate': 0.02, 'max_depth': 4, 'boosting': 'gbdt', 'objective': 'binary', 'is_training_metric': False, 'seed': 99}\n",
    "    params['boosting'] = 'dart'\n",
    "    params['metric'] = 'binary_logloss'\n",
    "    params['learning_rate'] = 0.04\n",
    "    params['max_depth'] = 5\n",
    "    params['num_leaves'] = 16 # higher number of leaves\n",
    "    params['feature_fraction'] = 0.8 # Controls overfit\n",
    "    params['bagging_fraction'] = 0.9    \n",
    "    params['bagging_freq'] = 3\n",
    "    params['seed'] = split_seed + r\n",
    "    #dart\n",
    "    params['drop_rate'] = 0.1\n",
    "    params['skip_drop'] = 0.5\n",
    "    params['max_drop'] = 10\n",
    "    params['verbose'] = -1 \n",
    "\n",
    "    file = STORE_PATH + 'subm_{}_lgb_{}_{:02d}.csv'.format(tmp, params['boosting'], r+1)\n",
    "    subms.append(file)\n",
    "\n",
    "    pred, f_tmp = run_lgb(params=params, \n",
    "                          lgb_train=lgb_train, \n",
    "                          lgb_valid=lgb_valid, \n",
    "                          lgb_test=test_X_dup, \n",
    "                          test_ids=test['id'].values, \n",
    "                          nr_round=nr_round, \n",
    "                          min_round=min_round, \n",
    "                          file=file)\n",
    "\n",
    "\n",
    "#blending\n",
    "preds = {k: 1.0 for k in subms}\n",
    "save_blend(preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
